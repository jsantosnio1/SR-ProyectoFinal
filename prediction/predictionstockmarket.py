# -*- coding: utf-8 -*-
"""PredictionStockMarket.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QhcpYSnlDqm8H1oCqWRRn2f9Tp6zXcOB

# 1. ¿Cuál fue el cambio en el precio de las acciones con el tiempo?

En esta sección, veremos cómo manejar la solicitud de información de acciones con pandas y cómo analizar los atributos básicos de una acción.
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np

import matplotlib.pyplot as plt
import seaborn as sns
sns.set_style('whitegrid')
plt.style.use("fivethirtyeight")
# %matplotlib inline

# For reading stock data from yahoo
from pandas_datareader.data import DataReader

# For time stamps
from datetime import datetime

# The tech stocks we'll use for this analysis
tech_list = ['AAPL', 'GOOG', 'MSFT', 'AMZN']

# Set up End and Start times for data grab
end = datetime.now()
start = datetime(end.year - 1, end.month, end.day)


#For loop for grabing yahoo finance data and setting as a dataframe
for stock in tech_list:   
    # Set DataFrame as the Stock Ticker
    globals()[stock] = DataReader(stock, 'yahoo', start, end)

"""Nota rápida: usar globals () es una forma descuidada de configurar los nombres de DataFrame, pero es simple

Sigamos adelante y juguemos con APPLE DataFrame para tener una idea de
"""

# for company, company_name in zip(company_list, tech_list):
#     company["company_name"] = company_name

company_list = [AAPL, GOOG, MSFT, AMZN]
company_name = ["APPLE", "GOOGLE", "MICROSOFT", "AMAZON"]

for company, com_name in zip(company_list, company_name):
    company["company_name"] = com_name
    
df = pd.concat(company_list, axis=0)
df.tail(10)

# Summary Stats
AAPL.describe()

# General info
AAPL.info()

# Veamos una vista histórica del precio de cierre

plt.figure(figsize=(15, 6))
plt.subplots_adjust(top=1.25, bottom=1.2)

for i, company in enumerate(company_list, 1):
    plt.subplot(2, 2, i)
    company['Adj Close'].plot()
    plt.ylabel('Adj Close')
    plt.xlabel(None)
    plt.title(f"Closing Price of {tech_list[i - 1]}")
    
plt.tight_layout()

# Ahora tracemos el volumen total de acciones que se negocian cada día.
plt.figure(figsize=(15, 7))
plt.subplots_adjust(top=1.25, bottom=1.2)

for i, company in enumerate(company_list, 1):
    plt.subplot(2, 2, i)
    company['Volume'].plot()
    plt.ylabel('Volume')
    plt.xlabel(None)
    plt.title(f"Sales Volume for {tech_list[i - 1]}")
    
plt.tight_layout()

"""# 2. ¿Cuál fue el promedio móvil de las distintas acciones?

---


"""

ma_day = [10, 20, 50]

for ma in ma_day:
    for company in company_list:
        column_name = f"MA for {ma} days"
        company[column_name] = company['Adj Close'].rolling(ma).mean()

# print(GOOG.columns)

"""Ahora sigamos adelante y grafiquemos todas las medias móviles adicionales."""

# df.groupby("company_name").hist(figsize=(12, 12));

fig, axes = plt.subplots(nrows=2, ncols=2)
fig.set_figheight(8)
fig.set_figwidth(15)

AAPL[['Adj Close', 'MA for 10 days', 'MA for 20 days', 'MA for 50 days']].plot(ax=axes[0,0])
axes[0,0].set_title('APPLE')

GOOG[['Adj Close', 'MA for 10 days', 'MA for 20 days', 'MA for 50 days']].plot(ax=axes[0,1])
axes[0,1].set_title('GOOGLE')

MSFT[['Adj Close', 'MA for 10 days', 'MA for 20 days', 'MA for 50 days']].plot(ax=axes[1,0])
axes[1,0].set_title('MICROSOFT')

AMZN[['Adj Close', 'MA for 10 days', 'MA for 20 days', 'MA for 50 days']].plot(ax=axes[1,1])
axes[1,1].set_title('AMAZON')

fig.tight_layout()

"""# 3. ¿Cuál fue el rendimiento diario de las acciones en promedio?

Ahora que hemos realizado un análisis de referencia, sigamos adelante y profundicemos un poco más. Ahora vamos a analizar el riesgo de la acción. Para hacerlo, tendremos que observar más de cerca los cambios diarios de la acción, y no solo su valor absoluto. Sigamos adelante y usemos pandas para recuperar los rendimientos diarios de las acciones de Apple.
"""

# Usaremos pct_change para encontrar el cambio porcentual de cada día
for company in company_list:
    company['Daily Return'] = company['Adj Close'].pct_change()

# Then we'll plot the daily return percentage
fig, axes = plt.subplots(nrows=2, ncols=2)
fig.set_figheight(8)
fig.set_figwidth(15)

AAPL['Daily Return'].plot(ax=axes[0,0], legend=True, linestyle='--', marker='o')
axes[0,0].set_title('APPLE')

GOOG['Daily Return'].plot(ax=axes[0,1], legend=True, linestyle='--', marker='o')
axes[0,1].set_title('GOOGLE')

MSFT['Daily Return'].plot(ax=axes[1,0], legend=True, linestyle='--', marker='o')
axes[1,0].set_title('MICROSOFT')

AMZN['Daily Return'].plot(ax=axes[1,1], legend=True, linestyle='--', marker='o')
axes[1,1].set_title('AMAZON')

fig.tight_layout()

"""Genial, ahora echemos un vistazo general al rendimiento diario promedio usando un histograma. Usaremos seaborn para crear un histograma y un diagrama kde en la misma figura."""

# Tenga en cuenta el uso de dropna () aquí, de lo contrario, seaborn no puede leer los valores de NaN
plt.figure(figsize=(12, 7))

for i, company in enumerate(company_list, 1):
    plt.subplot(2, 2, i)
    sns.distplot(company['Daily Return'].dropna(), bins=100, color='purple')
    plt.ylabel('Daily Return')
    plt.title(f'{company_name[i - 1]}')
# Could have also done:
#AAPL['Daily Return'].hist()
plt.tight_layout()

"""# 4. ¿Cuál fue la correlación entre los precios de cierre de las diferentes acciones?

Ahora, ¿y si quisiéramos analizar los rendimientos de todas las acciones de nuestra lista? Sigamos adelante y construyamos un DataFrame con todas las columnas ['Cerrar'] para cada uno de los dataframes de acciones.
"""

# Agarre todos los precios de cierre de la lista de acciones tecnológicas en un DataFrame
closing_df = DataReader(tech_list, 'yahoo', start, end)['Adj Close']
# Echemos un vistazo rápido
closing_df.head()

"""Ahora que tenemos todos los precios de cierre, sigamos adelante y obtengamos el diario

rendimiento de todas las acciones, como hicimos con las acciones de Apple.
"""

# Make a new tech returns DataFrame
tech_rets = closing_df.pct_change()
tech_rets.head()

"""Ahora podemos comparar el rendimiento porcentual diario de dos acciones para comprobar su correlación. Primero veamos una acción comparada con ella misma."""

# Comparing Google to itself should show a perfectly linear relationship
sns.jointplot('GOOG', 'GOOG', tech_rets, kind='scatter', color='seagreen')

# We'll use joinplot to compare the daily returns of Google and Microsoft
sns.jointplot('GOOG', 'MSFT', tech_rets, kind='scatter')

"""Así que ahora podemos ver que si dos acciones están perfectamente (y positivamente) correlacionadas entre sí, debería ocurrir una relación lineal entre sus valores de retorno diarios.

Seaborn y pandas facilitan la repetición de este análisis comparativo para cada combinación posible de acciones en nuestra lista de cotizaciones tecnológicas. Podemos usar sns.pairplot () para crear automáticamente este gráfico
"""

# Podemos simplemente llamar a pairplot en nuestro DataFrame para un análisis visual automático
# de todas las comparaciones

sns.pairplot(tech_rets, kind='reg')

"""Arriba podemos ver todas las relaciones de rentabilidad diaria entre todas las acciones. Un vistazo rápido muestra una correlación interesante entre los retornos diarios de Google y Amazon. Podría ser interesante investigar esa prisión en coma individual. Si bien la simplicidad de simplemente llamar a sns.pairplot () es fantástica, también podemos usar sns.PairGrid () para un control total de la figura, incluido el tipo de gráficos que van en la diagonal, el triángulo superior y el triángulo inferior. A continuación se muestra un ejemplo de cómo utilizar todo el poder de seaborn para lograr este resultado."""

# Set up our figure by naming it returns_fig, call PairPLot on the DataFrame
return_fig = sns.PairGrid(tech_rets.dropna())

# Using map_upper we can specify what the upper triangle will look like.
return_fig.map_upper(plt.scatter, color='purple')

# We can also define the lower triangle in the figure, inclufing the plot type (kde) 
# or the color map (BluePurple)
return_fig.map_lower(sns.kdeplot, cmap='cool_d')

# Finally we'll define the diagonal as a series of histogram plots of the daily return
return_fig.map_diag(plt.hist, bins=30)

# Set up our figure by naming it returns_fig, call PairPLot on the DataFrame
returns_fig = sns.PairGrid(closing_df)

# Using map_upper we can specify what the upper triangle will look like.
returns_fig.map_upper(plt.scatter,color='purple')

# We can also define the lower triangle in the figure, inclufing the plot type (kde) or the color map (BluePurple)
returns_fig.map_lower(sns.kdeplot,cmap='cool_d')

# Finally we'll define the diagonal as a series of histogram plots of the daily return
returns_fig.map_diag(plt.hist,bins=30)

"""Finalmente, también podríamos hacer un gráfico de correlación, para obtener valores numéricos reales para la correlación entre los valores de retorno diarios de las acciones. Al comparar los precios de cierre, vemos una relación interesante entre Microsoft y Apple."""

# Sigamos adelante y usemos sebron para una gráfica de correlación rápida para los rendimientos diarios
sns.heatmap(tech_rets.corr(), annot=True, cmap='summer')

sns.heatmap(closing_df.corr(), annot=True, cmap='summer')

"""¡Fantástico! Tal como sospechamos en nuestro PairPlot, vemos aquí numérica y visualmente que Microsoft y Amazon tenían la correlación más fuerte de rendimiento diario de acciones. También es interesante ver que todas las empresas de tecnología están correlacionadas positivamente.

# 5. ¿Cuánto valor ponemos en riesgo al invertir en una acción en particular?

Hay muchas formas en que podemos cuantificar el riesgo, una de las formas más básicas de utilizar la información que hemos recopilado sobre los rendimientos porcentuales diarios es comparando el rendimiento esperado con la desviación estándar de los rendimientos diarios.
"""

# Comencemos por definir un nuevo DataFrame como una versión más limpia del original tech_rets DataFrame
rets = tech_rets.dropna()

area = np.pi * 20

plt.figure(figsize=(10, 7))
plt.scatter(rets.mean(), rets.std(), s=area)
plt.xlabel('Expected return')
plt.ylabel('Risk')

for label, x, y in zip(rets.columns, rets.mean(), rets.std()):
    plt.annotate(label, xy=(x, y), xytext=(50, 50), textcoords='offset points', ha='right', va='bottom', 
                 arrowprops=dict(arrowstyle='-', color='blue', connectionstyle='arc3,rad=-0.3'))

"""# 6. Predicting the closing price stock price of APPLE inc:"""

# Obtenga la cotización de acciones
df = DataReader('AAPL', data_source='yahoo', start='2012-01-01', end=datetime.now())
# Mostrar los datos
df

plt.figure(figsize=(16,6))
plt.title('Close Price History')
plt.plot(df['Close'])
plt.xlabel('Date', fontsize=18)
plt.ylabel('Close Price USD ($)', fontsize=18)
plt.show()

# Cree un nuevo marco de datos con solo la columna 'Cerrar
data = df.filter(['Close'])
# Convierta el marco de datos en una matriz numpy
dataset = data.values
# Obtenga el número de filas en las que entrenar el modelo
training_data_len = int(np.ceil( len(dataset) * .95 ))

training_data_len

# Escalar los datos
from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler(feature_range=(0,1))
scaled_data = scaler.fit_transform(dataset)

scaled_data

# Crea el conjunto de datos de entrenamiento
# Crea el conjunto de datos de entrenamiento escalado
train_data = scaled_data[0:int(training_data_len), :]
# Divida los datos en conjuntos de datos x_train e y_train
x_train = []
y_train = []

for i in range(60, len(train_data)):
    x_train.append(train_data[i-60:i, 0])
    y_train.append(train_data[i, 0])
    if i<= 61:
        print(x_train)
        print(y_train)
        print()
        
# Convierta el x_train y y_train en matrices numpy
x_train, y_train = np.array(x_train), np.array(y_train)

# Remodelar los datos
x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))
# x_train.shape

from keras.models import Sequential
from keras.layers import Dense, LSTM

# Construye el modelo LSTM
model = Sequential()
model.add(LSTM(128, return_sequences=True, input_shape= (x_train.shape[1], 1)))
model.add(LSTM(64, return_sequences=False))
model.add(Dense(25))
model.add(Dense(1))

# Compilar la modelo
model.compile(optimizer='adam', loss='mean_squared_error')
# Entrenar al modelo
model.fit(x_train, y_train, batch_size=1, epochs=1)

# Cree el conjunto de datos de prueba
# Cree una nueva matriz que contenga valores escalados desde el índice 1543 hasta 2002
test_data = scaled_data[training_data_len - 60: , :]
# Cree los conjuntos de datos x_test y y_test
x_test = []
y_test = dataset[training_data_len:, :]
for i in range(60, len(test_data)):
    x_test.append(test_data[i-60:i, 0])
    
# Convierte los datos en una matriz numpy
x_test = np.array(x_test)

# Remodelar los datos
x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1 ))

# Obtenga los valores de precio predichos de los modelos
predictions = model.predict(x_test)
predictions = scaler.inverse_transform(predictions)

# Obtenga la raíz del error cuadrático medio (RMSE)
rmse = np.sqrt(np.mean(((predictions - y_test) ** 2)))
rmse

# Trazar los datos
train = data[:training_data_len]
valid = data[training_data_len:]
valid['Predictions'] = predictions
# Visualiza los datos
plt.figure(figsize=(16,6))
plt.title('Model')
plt.xlabel('Date', fontsize=18)
plt.ylabel('Close Price USD ($)', fontsize=18)
plt.plot(train['Close'])
plt.plot(valid[['Close', 'Predictions']])
plt.legend(['Train', 'Val', 'Predictions'], loc='lower right')
plt.show()

# Muestra los precios válidos y previstos
valid